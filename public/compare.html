<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width" />

    <title>Script processor node and Audio worklet node example</title>

    <link rel="stylesheet" href="" />
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>

  <body>
    <h1>Currently using <span id="apiType">----------</span></h1>

    <button id="play">Play song</button>
    <button id="pause">Pause song</button>
    <button id="stop">Stop song</button>

    <pre></pre>

    <script>
      const myScript = document.querySelector("script");
      const myPre = document.querySelector("pre");
      const playButton = document.getElementById("play");
      const pauseButton = document.getElementById("pause");
      const stopButton = document.getElementById("stop");

      // Create AudioContext and buffer source
      let audioCtx;
      let source;
      let rAF;

      function audioWorkletInit() {
        $("#apiType").text("Audio worklet");
        audioCtx = new AudioContext();
        source = audioCtx.createBufferSource();

        // load in an audio track via XHR and decodeAudioData

        function getData() {
          request = new XMLHttpRequest();
          request.open(
            "GET",
            "./50910__rutgermuller__in-car-driving.wav",
            true
          );
          request.responseType = "arraybuffer";
          request.onload = function() {
            let audioData = request.response;

            audioCtx.decodeAudioData(
              audioData,
              function(buffer) {
                myBuffer = buffer;
                source.buffer = myBuffer;
              },
              function(e) {
                "Error with decoding audio data" + e.err;
              }
            );
          };
          request.send();
        }

        getData();

        audioCtx.audioWorklet.addModule("./noise-generator.js").then(() => {
          const noiseGenerator = new AudioWorkletNode(
            audioCtx,
            "noise-generator"
          );
          source.connect(audioCtx.destination);
          noiseGenerator.connect(audioCtx.destination);
          source.start();
          rAF = requestAnimationFrame(outputTimestamps);
        });

        // // When the buffer source stops playing, disconnect everything
        // source.onended = function() {
        //   source.disconnect(scriptNode);
        //   scriptNode.disconnect(audioCtx.destination);
        // }
      }

      function init() {
        $("#apiType").text("Script Processor");
        audioCtx = new AudioContext();
        source = audioCtx.createBufferSource();

        // Create a ScriptProcessorNode with a bufferSize of 4096 and a single input and output channel
        let scriptNode = audioCtx.createScriptProcessor(4096, 1, 1);
        console.log(scriptNode.bufferSize);

        // load in an audio track via XHR and decodeAudioData

        function getData() {
          request = new XMLHttpRequest();
          request.open(
            "GET",
            "./50910__rutgermuller__in-car-driving.wav",
            true
          );
          request.responseType = "arraybuffer";
          request.onload = function() {
            let audioData = request.response;

            audioCtx.decodeAudioData(
              audioData,
              function(buffer) {
                myBuffer = buffer;
                source.buffer = myBuffer;
              },
              function(e) {
                "Error with decoding audio data" + e.err;
              }
            );
          };
          request.send();
        }

        // Give the node a function to process audio events
        scriptNode.onaudioprocess = function(audioProcessingEvent) {
          // The input buffer is the song we loaded earlier
          let inputBuffer = audioProcessingEvent.inputBuffer;

          // The output buffer contains the samples that will be modified and played
          let outputBuffer = audioProcessingEvent.outputBuffer;

          // Loop through the output channels (in this case there is only one)
          for (
            let channel = 0;
            channel < outputBuffer.numberOfChannels;
            channel++
          ) {
            let inputData = inputBuffer.getChannelData(channel);
            let outputData = outputBuffer.getChannelData(channel);

            // Loop through the 4096 samples
            for (let sample = 0; sample < inputBuffer.length; sample++) {
              // make output equal to the same as the input
              outputData[sample] = inputData[sample];

              // add noise to each output sample
              outputData[sample] += (Math.random() * 2 - 1) * 0.2;
            }
          }
        };

        getData();

        source.connect(scriptNode);
        scriptNode.connect(audioCtx.destination);
        source.start();
        rAF = requestAnimationFrame(outputTimestamps);

        // When the buffer source stops playing, disconnect everything
        source.onended = function() {
          source.disconnect(scriptNode);
          scriptNode.disconnect(audioCtx.destination);
        };
      }

      // wire up play button
      playButton.onclick = function() {
        if (!audioCtx) {
         // init();
          audioWorkletInit();
        }
      };

      pauseButton.onclick = function() {
        let that = this;
        if (audioCtx.state === "running") {
          audioCtx.suspend().then(function() {
            $(that).html("Resume song");
          });
        } else if (audioCtx.state === "suspended") {
          audioCtx.resume().then(function() {
            $(that).html("Pause song");
          });
        }
      };

      stopButton.onclick = function() {
        cancelAnimationFrame(rAF);
      };

      //output the script into the pre element
      myPre.innerHTML = myScript.innerHTML;

      function outputTimestamps() {
        let ts = audioCtx.getOutputTimestamp();
        console.log(
          "Context time: " +
            ts.contextTime +
            " | Performance time: " +
            ts.performanceTime
        );
        rAF = requestAnimationFrame(outputTimestamps);
      }
    </script>
  </body>
  <script
    src="https://code.jquery.com/jquery-3.4.1.min.js"
    integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
    crossorigin="anonymous"
  ></script>
</html>
